{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk0BE0Etlv+Ku57b9xnt3d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad-Usama-07/agentic_ai/blob/main/Different_Basic_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Packages"
      ],
      "metadata": {
        "id": "GRe8voREiPvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-openai python-dotenv langchain-groq\n",
        "!pip install -U langchain langchain-core langchain-community langchain-groq\n",
        "!pip install -U langchain langchain-core langchain-community langchain-groq langchain-classic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4pbwD_KiORw",
        "outputId": "53abb104-44f2-40f6-9424-a443331c6cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.4)\n",
            "Collecting langchain\n",
            "  Downloading langchain-1.2.7-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-1.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.7)\n",
            "Collecting langgraph<1.1.0,>=1.0.7 (from langchain)\n",
            "  Downloading langgraph-1.0.7-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.15.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.6.4)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.13.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.7 (from langgraph<1.1.0,>=1.0.7->langchain)\n",
            "  Downloading langgraph_prebuilt-1.0.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain-groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.7->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain-1.2.7-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.1.7-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-1.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading groq-0.37.1-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-1.0.7-py3-none-any.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.4/157.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.7-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: groq, langchain-openai, langchain-groq, langgraph-prebuilt, langgraph, langchain\n",
            "  Attempting uninstall: langgraph-prebuilt\n",
            "    Found existing installation: langgraph-prebuilt 1.0.6\n",
            "    Uninstalling langgraph-prebuilt-1.0.6:\n",
            "      Successfully uninstalled langgraph-prebuilt-1.0.6\n",
            "  Attempting uninstall: langgraph\n",
            "    Found existing installation: langgraph 1.0.6\n",
            "    Uninstalling langgraph-1.0.6:\n",
            "      Successfully uninstalled langgraph-1.0.6\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 1.2.4\n",
            "    Uninstalling langchain-1.2.4:\n",
            "      Successfully uninstalled langchain-1.2.4\n",
            "Successfully installed groq-0.37.1 langchain-1.2.7 langchain-groq-1.1.1 langchain-openai-1.1.7 langgraph-1.0.7 langgraph-prebuilt-1.0.7\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.7)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.7)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.6.4)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.13.0)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: groq<1.0.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (0.37.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.1 langchain-community-0.4.1 langchain-text-splitters-1.1.0 marshmallow-3.26.2 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.7)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.7)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: langchain-classic in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.6.4)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.13.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.45)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: groq<1.0.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (0.37.1)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic) (1.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents Description\n",
        "\n",
        "## Agent 1\n",
        "- Take question from the user\n",
        "- Give answer by using a tool(a method)"
      ],
      "metadata": {
        "id": "gP8dhLt4lBRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent 1 (Langchain + OpenAI)"
      ],
      "metadata": {
        "id": "UHCD0ZZoh6mB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### set key"
      ],
      "metadata": {
        "id": "OIF9_GOziYcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n"
      ],
      "metadata": {
        "id": "1HQSzdGOiX_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('aaa')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e405ky50bqE",
        "outputId": "e9526c22-b3b7-4ea8-8504-0f520d20a494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aaa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import tool\n",
        "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Define the tool\n",
        "@tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get weather for a given city.\"\"\"\n",
        "    return f\"It's always sunny in {city}!\"\n",
        "\n",
        "# LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# Prompt\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\")\n",
        "])\n",
        "\n",
        "# Create agent\n",
        "agent = create_openai_functions_agent(\n",
        "    llm=llm,\n",
        "    tools=[get_weather],\n",
        "    prompt=prompt\n",
        ")\n",
        "\n",
        "# Agent executor\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=[get_weather],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Run\n",
        "result = agent_executor.invoke({\n",
        "    \"input\": \"What is the weather in San Francisco?\"\n",
        "})\n",
        "\n",
        "print(result[\"output\"])\n"
      ],
      "metadata": {
        "id": "3diomiQpimco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent 1 (Langchain + Groq)"
      ],
      "metadata": {
        "id": "02K_2n5bk54x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\"\n"
      ],
      "metadata": {
        "id": "dvt7x5SLUlyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain.tools import tool\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "#\n",
        "# ------------------------- TOOL -------------------------\n",
        "@tool\n",
        "def get_code() -> str:\n",
        "    \"\"\"Returns a secret code unknown to the model.\"\"\"\n",
        "    print(\"TOOL EXECUTED: get_code\")\n",
        "    return \"cod-12345\"\n",
        "\n",
        "tools = [get_code]\n",
        "\n",
        "# ------------------------- LLM -------------------------\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# ------------------------- PROMPT -------------------------\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You do NOT know the secret code. \"\n",
        "        \"The ONLY way to get it is by calling the provided tool. \"\n",
        "        \"You MUST use the tool to answer.\"\n",
        "    ),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "# ------------------------- USER QUESTION -------------------------\n",
        "messages = prompt.invoke(\n",
        "    {\"input\": \"What is the secret code?\"}\n",
        ").to_messages()\n",
        "\n",
        "# ------------------------- STEP 1 (REQUEST TOOL) -------------------------\n",
        "response = llm_with_tools.invoke(messages)\n",
        "\n",
        "print(\"\\nModel response:\")\n",
        "print(response)\n",
        "\n",
        "# ------------------------- TOOL EXECUTION -------------------------\n",
        "if response.tool_calls:\n",
        "    tool_call = response.tool_calls[0]\n",
        "\n",
        "    print(\"\\nTool requested by model:\")\n",
        "    print(tool_call)\n",
        "\n",
        "    # Execute tool\n",
        "    tool_result = get_code.invoke(tool_call[\"args\"])\n",
        "\n",
        "    # ------------------------- STEP 2 (FINAL ANSWER) -------------------------\n",
        "    final_response = llm.invoke([\n",
        "        *messages,\n",
        "        response,\n",
        "        ToolMessage(\n",
        "            content=tool_result,\n",
        "            tool_call_id=tool_call[\"id\"]\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    print(\"\\nFINAL ANSWER:\")\n",
        "    print(final_response.content)\n",
        "else:\n",
        "    print(\"Model did NOT call the tool\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfDVaUV07-q9",
        "outputId": "ac462be8-9c4b-43e3-c901-4b6724353106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model response:\n",
            "content='' additional_kwargs={'tool_calls': [{'id': 'ymz3y8sag', 'function': {'arguments': '{}', 'name': 'get_code'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 242, 'total_tokens': 250, 'completion_time': 0.015676753, 'completion_tokens_details': None, 'prompt_time': 0.020151408, 'prompt_tokens_details': None, 'queue_time': 0.038662682, 'total_time': 0.035828161}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_bebe2dd4fb', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019bf4fb-ea3d-75f2-b8f9-a285683d45d7-0' tool_calls=[{'name': 'get_code', 'args': {}, 'id': 'ymz3y8sag', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 242, 'output_tokens': 8, 'total_tokens': 250}\n",
            "\n",
            "Tool requested by model:\n",
            "{'name': 'get_code', 'args': {}, 'id': 'ymz3y8sag', 'type': 'tool_call'}\n",
            "TOOL EXECUTED: get_code\n",
            "\n",
            "FINAL ANSWER:\n",
            "The secret code is cod-12345.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent 2 (Langchain + groq)\n",
        "\n",
        "1. Chatting with LLM\n",
        "2. calling tool to provide specific string\n"
      ],
      "metadata": {
        "id": "eBMEHtMuHmBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain.tools import tool\n",
        "from langchain_core.messages import ToolMessage, HumanMessage, AIMessage\n",
        "\n",
        "# ------------------------- TOOL -------------------------\n",
        "@tool\n",
        "def get_code() -> str:\n",
        "    \"\"\"Returns a secret code. Use ONLY when the user asks for the code or secret.\"\"\"\n",
        "    print(\"TOOL EXECUTED: get_code\")\n",
        "    return \"cod-12345\"\n",
        "\n",
        "tools = [get_code]\n",
        "\n",
        "# ------------------------- LLM -------------------------\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# ------------------------- SYSTEM PROMPT -------------------------\n",
        "system_prompt = (\n",
        "    \"You are a general-purpose assistant.\\n\"\n",
        "    \"- You can answer normal questions directly.\\n\"\n",
        "    \"- You do NOT know any secret or code.\\n\"\n",
        "    \"- If (and ONLY if) the user asks for a secret code, secret, or code, \"\n",
        "    \"you MUST call the provided tool to get it.\\n\"\n",
        "    \"- Do not call the tool for greetings or general conversation.\"\n",
        ")\n",
        "\n",
        "# ------------------------- CHAT LOOP -------------------------\n",
        "print(\"\\nAgent started\\n\")\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "while True:\n",
        "    print(\"\\nChoose an option:\")\n",
        "    print(\"1. Continue chatting\")\n",
        "    print(\"2.  Exit\")\n",
        "\n",
        "    choice = input(\"Enter 1 or 2: \").strip()\n",
        "\n",
        "    if choice == \"2\":\n",
        "        print(\"\\nExiting chat. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    elif choice == \"1\":\n",
        "        user_input = input(\"\\nYou: \").strip()\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            *chat_history,\n",
        "            HumanMessage(content=user_input)\n",
        "        ]\n",
        "\n",
        "        # -------- Step 1: Model decides\n",
        "        response = llm_with_tools.invoke(messages)\n",
        "\n",
        "        # -------- Step 2: Tool execution (ONLY if requested)\n",
        "        if response.tool_calls:\n",
        "            tool_call = response.tool_calls[0]\n",
        "\n",
        "            tool_result = get_code.invoke(tool_call[\"args\"])\n",
        "\n",
        "            final_response = llm.invoke([\n",
        "                *messages,\n",
        "                response,\n",
        "                ToolMessage(\n",
        "                    content=tool_result,\n",
        "                    tool_call_id=tool_call[\"id\"]\n",
        "                )\n",
        "            ])\n",
        "        else:\n",
        "            final_response = response\n",
        "\n",
        "        print(\"\\nAssistant:\", final_response.content)\n",
        "\n",
        "        chat_history.append(HumanMessage(content=user_input))\n",
        "        chat_history.append(AIMessage(content=final_response.content))\n",
        "\n",
        "    else:\n",
        "        print(\"\\nInvalid choice. Please enter 1 or 2.\")\n"
      ],
      "metadata": {
        "id": "3lGfmu4b8dlk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5538e16d-2885-4cd2-b391-c66b256daca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Agent started\n",
            "\n",
            "\n",
            "Choose an option:\n",
            "1. Continue chatting\n",
            "2.  Exit\n",
            "Enter 1 or 2: 1\n",
            "\n",
            "You: Hi\n",
            "\n",
            "Assistant: Hello. How can I assist you today?\n",
            "\n",
            "Choose an option:\n",
            "1. Continue chatting\n",
            "2.  Exit\n",
            "Enter 1 or 2: 2\n",
            "\n",
            "Exiting chat. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. close program when user say good bye or something?"
      ],
      "metadata": {
        "id": "jt9ziezCmQnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_groq import ChatGroq\n",
        "# from langchain.tools import tool\n",
        "# from langchain_core.messages import ToolMessage, HumanMessage, AIMessage\n",
        "\n",
        "# # ------------------------- TOOL -------------------------\n",
        "# @tool\n",
        "# def get_code() -> str:\n",
        "#     \"\"\"Returns a secret code. Use ONLY when the user asks for a secret or code.\"\"\"\n",
        "#     print(\"TOOL EXECUTED: get_code\")\n",
        "#     return \"cod-12345\"\n",
        "\n",
        "# tools = [get_code]\n",
        "\n",
        "# # ------------------------- LLM -------------------------\n",
        "# llm = ChatGroq(\n",
        "#     model=\"llama-3.3-70b-versatile\",\n",
        "#     temperature=0\n",
        "# )\n",
        "\n",
        "# llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# # ------------------------- SYSTEM PROMPT -------------------------\n",
        "# system_prompt = (\n",
        "#     \"You are a general-purpose assistant.\\n\"\n",
        "#     \"- You can answer normal questions directly.\\n\"\n",
        "#     \"- You do NOT know any secret or code.\\n\"\n",
        "#     \"- ONLY if the user asks for a secret or code, you MUST call the tool.\\n\"\n",
        "#     \"- Do NOT call the tool for greetings or general conversation.\"\n",
        "# )\n",
        "\n",
        "# # ------------------------- EXIT WORDS -------------------------\n",
        "# exit_words = {\"bye\", \"goodbye\", \"exit\", \"quit\", \"stop\"}\n",
        "\n",
        "# # ------------------------- CHAT LOOP -------------------------\n",
        "# print(\"Agent started. Type 'bye' to exit.\\n\")\n",
        "\n",
        "# chat_history = []\n",
        "\n",
        "# while True:\n",
        "#     user_input = input(\"You: \").strip()\n",
        "\n",
        "#     if user_input.lower() in exit_words:\n",
        "#         print(\"\\nAssistant: Goodbye! Have a great day.\")\n",
        "#         break\n",
        "\n",
        "#     messages = [\n",
        "#         {\"role\": \"system\", \"content\": system_prompt},\n",
        "#         *chat_history,\n",
        "#         HumanMessage(content=user_input)\n",
        "#     ]\n",
        "\n",
        "#     # Step 1: Model decides\n",
        "#     response = llm_with_tools.invoke(messages)\n",
        "\n",
        "#     # Step 2: Execute tool only if requested\n",
        "#     if response.tool_calls:\n",
        "#         tool_call = response.tool_calls[0]\n",
        "#         tool_result = get_code.invoke(tool_call[\"args\"])\n",
        "\n",
        "#         final_response = llm.invoke([\n",
        "#             *messages,\n",
        "#             response,\n",
        "#             ToolMessage(\n",
        "#                 content=tool_result,\n",
        "#                 tool_call_id=tool_call[\"id\"]\n",
        "#             )\n",
        "#         ])\n",
        "#     else:\n",
        "#         final_response = response\n",
        "\n",
        "#     print(\"\\nAssistant:\", final_response.content, \"\\n\")\n",
        "\n",
        "#     chat_history.append(HumanMessage(content=user_input))\n",
        "#     chat_history.append(AIMessage(content=final_response.content))\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.tools import tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
        "\n",
        "# -------------------- TOOL --------------------\n",
        "@tool\n",
        "def get_code() -> str:\n",
        "    \"\"\"Returns a secret code. Use ONLY when the user asks for a code or secret.\"\"\"\n",
        "    print(\"TOOL EXECUTED: get_code\")\n",
        "    return \"cod-12345\"\n",
        "\n",
        "tools = [get_code]\n",
        "\n",
        "# -------------------- MODELS --------------------\n",
        "chat_llm = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "judge_llm = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "chat_llm_with_tools = chat_llm.bind_tools(tools)\n",
        "\n",
        "# -------------------- EXIT DETECTION FUNCTION --------------------\n",
        "def should_exit(user_input: str) -> bool:\n",
        "    \"\"\"\n",
        "    Uses the LLM to decide if the user wants to end the conversation.\n",
        "    Returns True if the intent is to exit, otherwise False.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an intent classifier.\n",
        "    Decide if the following message means the user wants to END the conversation.\n",
        "\n",
        "    User message:\n",
        "    \"{user_input}\"\n",
        "\n",
        "    Reply with ONLY one word:\n",
        "    YES or NO\n",
        "    \"\"\"\n",
        "\n",
        "    response = judge_llm.invoke(prompt).content.strip().upper()\n",
        "    return response == \"YES\"\n",
        "\n",
        "# -------------------- SYSTEM PROMPT --------------------\n",
        "system_prompt = (\n",
        "    \"You are a helpful general-purpose assistant.\\n\"\n",
        "    \"You can answer any normal question.\\n\"\n",
        "    \"You do NOT know any secret or code.\\n\"\n",
        "    \"ONLY if the user asks for a secret or code, you MUST call the tool.\\n\"\n",
        ")\n",
        "\n",
        "# -------------------- CHAT LOOP --------------------\n",
        "print(\"Agent started. Chat freely — say anything when you want to leave.\\n\")\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \").strip()\n",
        "\n",
        "    # LLM decides whether to exit\n",
        "    if should_exit(user_input):\n",
        "        print(\"\\nAssistant: Goodbye! Take care.\")\n",
        "        break\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        *chat_history,\n",
        "        HumanMessage(content=user_input)\n",
        "    ]\n",
        "\n",
        "    response = chat_llm_with_tools.invoke(messages)\n",
        "\n",
        "    if response.tool_calls:\n",
        "        tool_call = response.tool_calls[0]\n",
        "        tool_result = get_code.invoke(tool_call[\"args\"])\n",
        "\n",
        "        final_response = chat_llm.invoke([\n",
        "            *messages,\n",
        "            response,\n",
        "            ToolMessage(\n",
        "                content=tool_result,\n",
        "                tool_call_id=tool_call[\"id\"]\n",
        "            )\n",
        "        ])\n",
        "    else:\n",
        "        final_response = response\n",
        "\n",
        "    print(\"\\nAssistant:\", final_response.content, \"\\n\")\n",
        "\n",
        "    chat_history.append(HumanMessage(content=user_input))\n",
        "    chat_history.append(AIMessage(content=final_response.content))\n"
      ],
      "metadata": {
        "id": "48lW3FoQXzkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "494632dd-5d11-4013-f64e-65ef2abe1af2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent started. Chat freely — say anything when you want to leave.\n",
            "\n",
            "You: Hello \n",
            "\n",
            "Assistant: Hello. How can I assist you today? \n",
            "\n",
            "You: who are yoo\n",
            "\n",
            "Assistant: I'm a helpful general-purpose assistant. I can provide information, answer questions, and help with a wide range of topics. I'm here to assist you with anything you need, so feel free to ask me anything. How can I help you today? \n",
            "\n",
            "You: what are you doing\n",
            "\n",
            "Assistant: I'm currently chatting with you and waiting for your questions or topics you'd like to discuss. I'm ready to provide information, answer questions, and help with anything you need. What's on your mind? \n",
            "\n",
            "You: ok, thanks bye\n",
            "\n",
            "Assistant: Goodbye! Take care.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qMUhPeWAjNRK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}