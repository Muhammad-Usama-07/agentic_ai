{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVNDxmy67A6t1v6W/5V7Rm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad-Usama-07/agentic_ai/blob/main/Different_Basic_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Packages"
      ],
      "metadata": {
        "id": "GRe8voREiPvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-openai python-dotenv langchain-groq\n",
        "!pip install -U langchain langchain-core langchain-community langchain-groq\n",
        "!pip install -U langchain langchain-core langchain-community langchain-groq langchain-classic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4pbwD_KiORw",
        "outputId": "6762ccc2-3e6c-4d8e-ed74-7b30dc72b8f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.7)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.7)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.7)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.15.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: groq<1.0.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (0.37.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.6.4)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.7->langchain) (0.13.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain-groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.7->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.7->langchain) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents Description\n",
        "\n",
        "## Agent 1\n",
        "- Take question from the user\n",
        "- Give answer by using a tool(a method)"
      ],
      "metadata": {
        "id": "gP8dhLt4lBRq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent 1 (Langchain + OpenAI)"
      ],
      "metadata": {
        "id": "UHCD0ZZoh6mB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### set key"
      ],
      "metadata": {
        "id": "OIF9_GOziYcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n"
      ],
      "metadata": {
        "id": "1HQSzdGOiX_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('aaa')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e405ky50bqE",
        "outputId": "e9526c22-b3b7-4ea8-8504-0f520d20a494"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aaa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.tools import tool\n",
        "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Define the tool\n",
        "@tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get weather for a given city.\"\"\"\n",
        "    return f\"It's always sunny in {city}!\"\n",
        "\n",
        "# LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# Prompt\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"placeholder\", \"{agent_scratchpad}\")\n",
        "])\n",
        "\n",
        "# Create agent\n",
        "agent = create_openai_functions_agent(\n",
        "    llm=llm,\n",
        "    tools=[get_weather],\n",
        "    prompt=prompt\n",
        ")\n",
        "\n",
        "# Agent executor\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=[get_weather],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Run\n",
        "result = agent_executor.invoke({\n",
        "    \"input\": \"What is the weather in San Francisco?\"\n",
        "})\n",
        "\n",
        "print(result[\"output\"])\n"
      ],
      "metadata": {
        "id": "3diomiQpimco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent 1 (Langchain + Groq)"
      ],
      "metadata": {
        "id": "02K_2n5bk54x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\"\n"
      ],
      "metadata": {
        "id": "dvt7x5SLUlyi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "from langchain.tools import tool\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.messages import ToolMessage\n",
        "\n",
        "#\n",
        "# ------------------------- TOOL -------------------------\n",
        "@tool\n",
        "def get_code() -> str:\n",
        "    \"\"\"Returns a secret code unknown to the model.\"\"\"\n",
        "    print(\"TOOL EXECUTED: get_code\")\n",
        "    return \"cod-12345\"\n",
        "\n",
        "tools = [get_code]\n",
        "\n",
        "# ------------------------- LLM -------------------------\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# ------------------------- PROMPT -------------------------\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You do NOT know the secret code. \"\n",
        "        \"The ONLY way to get it is by calling the provided tool. \"\n",
        "        \"You MUST use the tool to answer.\"\n",
        "    ),\n",
        "    (\"human\", \"{input}\")\n",
        "])\n",
        "\n",
        "# ------------------------- USER QUESTION -------------------------\n",
        "messages = prompt.invoke(\n",
        "    {\"input\": \"What is the secret code?\"}\n",
        ").to_messages()\n",
        "\n",
        "# ------------------------- STEP 1 (REQUEST TOOL) -------------------------\n",
        "response = llm_with_tools.invoke(messages)\n",
        "\n",
        "print(\"\\nModel response:\")\n",
        "print(response)\n",
        "\n",
        "# ------------------------- TOOL EXECUTION -------------------------\n",
        "if response.tool_calls:\n",
        "    tool_call = response.tool_calls[0]\n",
        "\n",
        "    print(\"\\nTool requested by model:\")\n",
        "    print(tool_call)\n",
        "\n",
        "    # Execute tool\n",
        "    tool_result = get_code.invoke(tool_call[\"args\"])\n",
        "\n",
        "    # ------------------------- STEP 2 (FINAL ANSWER) -------------------------\n",
        "    final_response = llm.invoke([\n",
        "        *messages,\n",
        "        response,\n",
        "        ToolMessage(\n",
        "            content=tool_result,\n",
        "            tool_call_id=tool_call[\"id\"]\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    print(\"\\nFINAL ANSWER:\")\n",
        "    print(final_response.content)\n",
        "else:\n",
        "    print(\"Model did NOT call the tool\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfDVaUV07-q9",
        "outputId": "ac462be8-9c4b-43e3-c901-4b6724353106"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model response:\n",
            "content='' additional_kwargs={'tool_calls': [{'id': 'ymz3y8sag', 'function': {'arguments': '{}', 'name': 'get_code'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 242, 'total_tokens': 250, 'completion_time': 0.015676753, 'completion_tokens_details': None, 'prompt_time': 0.020151408, 'prompt_tokens_details': None, 'queue_time': 0.038662682, 'total_time': 0.035828161}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_bebe2dd4fb', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019bf4fb-ea3d-75f2-b8f9-a285683d45d7-0' tool_calls=[{'name': 'get_code', 'args': {}, 'id': 'ymz3y8sag', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 242, 'output_tokens': 8, 'total_tokens': 250}\n",
            "\n",
            "Tool requested by model:\n",
            "{'name': 'get_code', 'args': {}, 'id': 'ymz3y8sag', 'type': 'tool_call'}\n",
            "TOOL EXECUTED: get_code\n",
            "\n",
            "FINAL ANSWER:\n",
            "The secret code is cod-12345.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3lGfmu4b8dlk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}